{"cells":[{"source":"# House sales\n\nRealAgents is a real estate company that focuses on selling houses.\n\nRealAgents sells a variety of types of house in one metropolitan area.\n\nSome houses sell slowly and sometimes require lowering the price in order to find a buyer.\n\nIn order to stay competitive, RealAgents would like to optimize the listing prices of the houses it is trying to sell.\n\nThey want to do this by predicting the sale price of a house given its characteristics.\n\nIf they can predict the sale price in advance, they can decrease the time to sale.\n\n\n## Data\n\nThe dataset contains records of previous houses sold in the area.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n| house_id    | Nominal. </br> Unique identifier for houses. </br>Missing values not possible. |\n| city        | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton'. </br>Replace missing values with \"Unknown\". |\n| sale_price  | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries. |\n| sale_date   | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01. |\n| months_listed  | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n| bedrooms    | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer. |\n| house_type   | Ordinal. </br>One of \"Terraced\" (two shared walls), \"Semi-detached\" (one shared wall), or \"Detached\" (no shared walls). </br>Replace missing values with the most common house type. |\n| area      | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place. |\n","metadata":{},"id":"e33eda06-7d7d-445e-8cd0-60b4d4b13afb","cell_type":"markdown"},{"source":"# Task 1\n\nThe team at RealAgents knows that the city that a property is located in makes a difference to the sale price. \n\nUnfortuntately they believe that this isn't always recorded in the data. \n\nCalculate the number of missing values of the `city`. \n\n - You should use the data in the file \"house_sales.csv\". \n\n - Your output should be an object `missing_city`, that contains the number of missing values in this column. ","metadata":{},"id":"ce597564-6bd3-4f54-830b-d5bac083c04a","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 1\nimport pandas as pd\n\nhouses = pd.read_csv(\"house_sales.csv\", parse_dates= [\"sale_date\"])\n\nhouses.isna().sum()    # 31 NaNs in months_listed\n\ncity_cond = houses[\"city\"].isin(['Silvertown', 'Riverford', 'Teasdale', 'Poppleton'])\n\nmissing_city = len(houses[~city_cond])\n\nprint(missing_city)","metadata":{"executionCancelledAt":null,"executionTime":18,"lastExecutedAt":1709603567194,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 1\nimport pandas as pd\n\nhouses = pd.read_csv(\"house_sales.csv\", parse_dates= [\"sale_date\"])\n\nhouses.isna().sum()    # 31 NaNs in months_listed\n\ncity_cond = houses[\"city\"].isin(['Silvertown', 'Riverford', 'Teasdale', 'Poppleton'])\n\nmissing_city = len(houses[~city_cond])\n\nprint(missing_city)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"id":"b2cb73bf-bb81-4664-b3eb-c35f6914a652","cell_type":"code","execution_count":166,"outputs":[{"output_type":"stream","name":"stdout","text":"73\n"}]},{"source":"# Task 2 \n\nBefore you fit any models, you will need to make sure the data is clean. \n\nThe table below shows what the data should look like. \n\nCreate a cleaned version of the dataframe. \n\n - You should start with the data in the file \"house_sales.csv\". \n\n - Your output should be a dataframe named `clean_data`. \n\n - All column names and values should match the table below.\n\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n| house_id    | Nominal. </br> Unique identifier for houses. </br>Missing values not possible. |\n| city        | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton' </br>Replace missing values with \"Unknown\". |\n| sale_price  | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries. |\n| sale_date   | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01. |\n| months_listed  | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n| bedrooms    | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer. |\n| house_type   | Ordinal. </br>One of \"Terraced\", \"Semi-detached\", or \"Detached\". </br>Replace missing values with the most common house type. |\n| area      | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place. |","metadata":{},"id":"5045c039-b353-46ba-87b9-af63aaa4abf3","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 2\nimport pandas as pd\nimport numpy as np\n\n#houses = pd.read_csv(\"house_sales.csv\", parse_dates= [\"sale_date\"])\nhouses = pd.read_csv(\"house_sales.csv\")\nclean_data = houses.copy()\n\n# Change column names\nnew_names = {\n    'house_id': 'house_id' ,\n    'city': 'city',\n    'sale_price': 'sale_price',\n    'sale_date': 'sale_date' ,\n    'months_listed': 'months_listed',\n    'bedrooms': 'bedrooms',\n    'house_type': 'house_type' ,\n    'area': 'area'\n}\n\n# Rename columns using the dictionary\nclean_data.rename(columns=new_names, inplace=True)\n\n# Fill missing data\ncity_cond = clean_data[\"city\"].isin(['Silvertown', 'Riverford', 'Teasdale', 'Poppleton'])\n\n# fill city '--' missing values with \"Unkown\"\nclean_data.loc[~city_cond, \"city\"] = None\nclean_data[\"city\"].fillna(\"Unknown\", inplace= True)\n\n# sale_price: drop NaNs entries\nclean_data.dropna(subset=['sale_price'], inplace= True)\n\n# sale_date: fill with \"2023-01-01\"\n#clean_data[\"sale_date\"] = clean_data[\"sale_date\"].dt.date\nclean_data[\"sale_date\"].fillna(\"2023-01-01\")\n\n# months_mean: fill with mean rouded to 1 decimal, and round all rows to 1 deciaml\nmonths_mean = np.round(clean_data[\"months_listed\"].mean(), 1)\nclean_data[\"months_listed\"].fillna(months_mean, inplace= True)\nclean_data[\"months_listed\"] = np.round(clean_data[\"months_listed\"], 1)\n\n# bedrooms: replace missing values with the mean number of bedrooms, rounded to the nearest integer\nbedrooms_mean = np.round(clean_data[\"bedrooms\"].mean())\nclean_data[\"bedrooms\"].fillna(bedrooms_mean, inplace= True)\n\n\n# house_type: \n    # 1.first collapse similar categories into the correct ones\nmapping = {\n    'Det.': 'Detached',\n    'Semi': 'Semi-detached',\n    'Terr.': 'Terraced'\n}\nclean_data['house_type'] = clean_data['house_type'].replace(mapping)\n#clean_data[\"house_type\"].unique()\n\n    # 2. replace missing values with the most common house type.\nmost_common = clean_data[\"house_type\"].value_counts(sort=True).idxmax()\nclean_data[\"house_type\"].fillna(most_common, inplace=True)\n\n# area: Replace missing values with the mean, to one decimal place. Round all rows to one decimal place\n    # 1. clean string data and convert to numeric\nclean_data[\"area\"]= clean_data[\"area\"].str.strip(\"sq.m.\")\nclean_data[\"area\"]= clean_data[\"area\"].astype(float)\n\n    # 2. fill NaNs with mean\narea_mean = np.round(clean_data[\"area\"].mean(), 1)\nclean_data[\"area\"].fillna(area_mean, inplace=True)\n\n# Change data types\n\n    # Set house_type category order\ncategory_order = ['Terraced', 'Semi-detached', 'Detached']\n\n    # Convert 'house_type' column to ordinal categorical data\nclean_data['house_type'] = pd.Categorical(clean_data['house_type'], \n                                          categories=category_order, \n                                          ordered=True)\n\ntypes = {\n    'house_id': 'int64' ,\n    'city': 'category',\n    'sale_price': 'int64',\n    'months_listed': 'float64',\n    'bedrooms': 'int64',\n    'area': 'float64'\n}\nclean_data = clean_data.astype(types)\n\n#print(clean_data.info())\n\n#for column in list(clean_data.columns):\n#    print(\"\\nUnique Values for {}:\".format(column))\n#    print(clean_data[column].unique())\n\n# Display resulting dataframe\nprint(clean_data)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1709603567246,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 2\nimport pandas as pd\nimport numpy as np\n\n#houses = pd.read_csv(\"house_sales.csv\", parse_dates= [\"sale_date\"])\nhouses = pd.read_csv(\"house_sales.csv\")\nclean_data = houses.copy()\n\n# Change column names\nnew_names = {\n    'house_id': 'house_id' ,\n    'city': 'city',\n    'sale_price': 'sale_price',\n    'sale_date': 'sale_date' ,\n    'months_listed': 'months_listed',\n    'bedrooms': 'bedrooms',\n    'house_type': 'house_type' ,\n    'area': 'area'\n}\n\n# Rename columns using the dictionary\nclean_data.rename(columns=new_names, inplace=True)\n\n# Fill missing data\ncity_cond = clean_data[\"city\"].isin(['Silvertown', 'Riverford', 'Teasdale', 'Poppleton'])\n\n# fill city '--' missing values with \"Unkown\"\nclean_data.loc[~city_cond, \"city\"] = None\nclean_data[\"city\"].fillna(\"Unknown\", inplace= True)\n\n# sale_price: drop NaNs entries\nclean_data.dropna(subset=['sale_price'], inplace= True)\n\n# sale_date: fill with \"2023-01-01\"\n#clean_data[\"sale_date\"] = clean_data[\"sale_date\"].dt.date\nclean_data[\"sale_date\"].fillna(\"2023-01-01\")\n\n# months_mean: fill with mean rouded to 1 decimal, and round all rows to 1 deciaml\nmonths_mean = np.round(clean_data[\"months_listed\"].mean(), 1)\nclean_data[\"months_listed\"].fillna(months_mean, inplace= True)\nclean_data[\"months_listed\"] = np.round(clean_data[\"months_listed\"], 1)\n\n# bedrooms: replace missing values with the mean number of bedrooms, rounded to the nearest integer\nbedrooms_mean = np.round(clean_data[\"bedrooms\"].mean())\nclean_data[\"bedrooms\"].fillna(bedrooms_mean, inplace= True)\n\n\n# house_type: \n    # 1.first collapse similar categories into the correct ones\nmapping = {\n    'Det.': 'Detached',\n    'Semi': 'Semi-detached',\n    'Terr.': 'Terraced'\n}\nclean_data['house_type'] = clean_data['house_type'].replace(mapping)\n#clean_data[\"house_type\"].unique()\n\n    # 2. replace missing values with the most common house type.\nmost_common = clean_data[\"house_type\"].value_counts(sort=True).idxmax()\nclean_data[\"house_type\"].fillna(most_common, inplace=True)\n\n# area: Replace missing values with the mean, to one decimal place. Round all rows to one decimal place\n    # 1. clean string data and convert to numeric\nclean_data[\"area\"]= clean_data[\"area\"].str.strip(\"sq.m.\")\nclean_data[\"area\"]= clean_data[\"area\"].astype(float)\n\n    # 2. fill NaNs with mean\narea_mean = np.round(clean_data[\"area\"].mean(), 1)\nclean_data[\"area\"].fillna(area_mean, inplace=True)\n\n# Change data types\n\n    # Set house_type category order\ncategory_order = ['Terraced', 'Semi-detached', 'Detached']\n\n    # Convert 'house_type' column to ordinal categorical data\nclean_data['house_type'] = pd.Categorical(clean_data['house_type'], \n                                          categories=category_order, \n                                          ordered=True)\n\ntypes = {\n    'house_id': 'int64' ,\n    'city': 'category',\n    'sale_price': 'int64',\n    'months_listed': 'float64',\n    'bedrooms': 'int64',\n    'area': 'float64'\n}\nclean_data = clean_data.astype(types)\n\n#print(clean_data.info())\n\n#for column in list(clean_data.columns):\n#    print(\"\\nUnique Values for {}:\".format(column))\n#    print(clean_data[column].unique())\n\n# Display resulting dataframe\nprint(clean_data)","outputsMetadata":{"0":{"height":297,"type":"stream"}}},"id":"dc9c2344-a350-461c-b5db-40768b2165a5","cell_type":"code","execution_count":167,"outputs":[{"output_type":"stream","name":"stdout","text":"      house_id        city  sale_price  ... bedrooms     house_type   area\n0      1217792  Silvertown       55943  ...        2  Semi-detached  107.8\n1      1900913  Silvertown      384677  ...        5       Detached  498.8\n2      1174927   Riverford      281707  ...        6       Detached  542.5\n3      1773666  Silvertown      373251  ...        6       Detached  528.4\n4      1258487  Silvertown      328885  ...        5       Detached  477.1\n...        ...         ...         ...  ...      ...            ...    ...\n1495   1123892   Riverford      198661  ...        5       Detached  432.2\n1496   1327295   Poppleton      358304  ...        6       Detached  599.8\n1497   1058161   Riverford      176612  ...        4       Detached  359.1\n1498   1822037    Teasdale      197827  ...        3       Detached  253.7\n1499   1679272   Poppleton      162099  ...        3       Detached  268.7\n\n[1500 rows x 8 columns]\n"}]},{"source":"# Task 3 \n\nThe team at RealAgents have told you that they have always believed that the number of bedrooms is the biggest driver of house price. \n\nProducing a table showing the difference in the average sale price by number of bedrooms along with the variance to investigate this question for the team.\n\n - You should start with the data in the file 'house_sales.csv'.\n\n - Your output should be a data frame named `price_by_rooms`. \n\n - It should include the three columns `bedrooms`, `avg_price`, `var_price`. \n\n - Your answers should be rounded to 1 decimal place.   ","metadata":{},"id":"ff3c2889-66f3-4a6b-acac-2b12626e3244","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 3\n\nhouses = pd.read_csv(\"house_sales.csv\")\n\nprice_by_rooms = houses.groupby(\"bedrooms\")[\"sale_price\"].agg(['mean', 'var']).reset_index()\n\ncolumn_names = {'mean': 'avg_price', 'var': 'var_price'}\nprice_by_rooms = np.round(price_by_rooms.rename(columns = column_names), 1)\n\nprice_by_rooms","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1709603567294,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 3\n\nhouses = pd.read_csv(\"house_sales.csv\")\n\nprice_by_rooms = houses.groupby(\"bedrooms\")[\"sale_price\"].agg(['mean', 'var']).reset_index()\n\ncolumn_names = {'mean': 'avg_price', 'var': 'var_price'}\nprice_by_rooms = np.round(price_by_rooms.rename(columns = column_names), 1)\n\nprice_by_rooms","outputsMetadata":{"0":{"height":198,"type":"dataFrame"}}},"id":"ea512a1c-e512-4f2e-8d78-323e51d01407","cell_type":"code","execution_count":168,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"bedrooms","type":"integer"},{"name":"avg_price","type":"number"},{"name":"var_price","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"bedrooms":[2,3,4,5,6],"avg_price":[67076.4,154665.1,234704.6,301515.9,375741.3],"var_price":[565289569.7,2378289076.9,1725211191.5,2484327529,3924432279.5]}},"total_rows":5,"truncation_type":null},"text/plain":"   bedrooms  avg_price     var_price\n0         2    67076.4  5.652896e+08\n1         3   154665.1  2.378289e+09\n2         4   234704.6  1.725211e+09\n3         5   301515.9  2.484328e+09\n4         6   375741.3  3.924432e+09","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bedrooms</th>\n      <th>avg_price</th>\n      <th>var_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>67076.4</td>\n      <td>5.652896e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>154665.1</td>\n      <td>2.378289e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>234704.6</td>\n      <td>1.725211e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>301515.9</td>\n      <td>2.484328e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>375741.3</td>\n      <td>3.924432e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":168}]},{"source":"# Task 4\n\nFit a baseline model to predict the sale price of a house.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `house_id` and `price`. The price column must be your predicted values.","metadata":{},"id":"ac7038d1-7a8f-4d97-aef1-36f3f1227374","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 4\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('validation.csv')\n\n#train_clean = data_cleaner(train)\n#test_clean = data_cleaner(test)\ntrain_clean = train\ntest_clean = test\n#print(train_clean.equals(train))\n#print(test_clean.equals(test))\n\n        # All data seem to be already clean\n\n#for column in list(test.columns):\n#    print(\"\\nUnique Values for {}:\".format(column))\n#    print(test[column].unique())\n    \n#test.isna().sum()\n\ndef transform_data(data):\n    new_data= data.copy()\n    \n    # Drop iD column\n    new_data = new_data.drop(\"house_id\", axis=1)\n    \n    # Get dummy variables for city and house_type\n    new_data = pd.get_dummies(new_data, columns = [\"city\", \"house_type\"])\n    \n    # Extract useful information from sale_date column\n    new_data[\"sale_date\"] = pd.to_datetime(new_data['sale_date'])\n    new_data[\"year\"] = new_data[\"sale_date\"].dt.year\n    new_data[\"month\"] = new_data[\"sale_date\"].dt.month\n    new_data[\"day\"] = new_data[\"sale_date\"].dt.day\n    \n    new_data = new_data.drop(\"sale_date\", axis=1)\n            \n    return new_data\n        \ntrain_clean = transform_data(train_clean)\ntest_clean = transform_data(test_clean)\n\n# Split train_clean into X_train and y_train\nX_train = train_clean.drop(\"sale_price\", axis=1).values\ny_train = train_clean[\"sale_price\"].values\n\nX_test = test_clean.values\n\n# Create and fit model\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nbase_result = pd.DataFrame({'house_id': test[\"house_id\"], 'price': y_pred})\n\n# Display the resulting dataframe\nprint(base_result)\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1709603567347,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 4\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('validation.csv')\n\n#train_clean = data_cleaner(train)\n#test_clean = data_cleaner(test)\ntrain_clean = train\ntest_clean = test\n#print(train_clean.equals(train))\n#print(test_clean.equals(test))\n\n        # All data seem to be already clean\n\n#for column in list(test.columns):\n#    print(\"\\nUnique Values for {}:\".format(column))\n#    print(test[column].unique())\n    \n#test.isna().sum()\n\ndef transform_data(data):\n    new_data= data.copy()\n    \n    # Drop iD column\n    new_data = new_data.drop(\"house_id\", axis=1)\n    \n    # Get dummy variables for city and house_type\n    new_data = pd.get_dummies(new_data, columns = [\"city\", \"house_type\"])\n    \n    # Extract useful information from sale_date column\n    new_data[\"sale_date\"] = pd.to_datetime(new_data['sale_date'])\n    new_data[\"year\"] = new_data[\"sale_date\"].dt.year\n    new_data[\"month\"] = new_data[\"sale_date\"].dt.month\n    new_data[\"day\"] = new_data[\"sale_date\"].dt.day\n    \n    new_data = new_data.drop(\"sale_date\", axis=1)\n            \n    return new_data\n        \ntrain_clean = transform_data(train_clean)\ntest_clean = transform_data(test_clean)\n\n# Split train_clean into X_train and y_train\nX_train = train_clean.drop(\"sale_price\", axis=1).values\ny_train = train_clean[\"sale_price\"].values\n\nX_test = test_clean.values\n\n# Create and fit model\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nbase_result = pd.DataFrame({'house_id': test[\"house_id\"], 'price': y_pred})\n\n# Display the resulting dataframe\nprint(base_result)\n","outputsMetadata":{"0":{"height":297,"type":"stream"},"1":{"height":323,"type":"dataFrame"}}},"id":"96496c59-fdd4-4683-9884-551ad93b788f","cell_type":"code","execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":"     house_id          price\n0     1331375  121450.319429\n1     1630115  304384.498235\n2     1645745  384629.788665\n3     1336775  124804.725941\n4     1888274  271216.164572\n..        ...            ...\n295   1986255  349810.906432\n296   1896276  369221.549578\n297   1758223  257517.739299\n298   1752010  169452.990144\n299   1651404  389009.461825\n\n[300 rows x 2 columns]\n"}]},{"source":"# Task 5\n\nFit a comparison model to predict the sale price of a house.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `house_id` and `price`. The price column must be your predicted values.","metadata":{},"id":"7c674c01-d6de-488d-b2e0-bc3bbf87def6","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 5\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('validation.csv')\n\n#train_clean = data_cleaner(train)\n#test_clean = data_cleaner(test)\ntrain_clean = train\ntest_clean = test\n#print(train_clean.equals(train))\n#print(test_clean.equals(test))\n\n        # All data seem to be already clean\n\ndef transform_data(data):\n    new_data= data.copy()\n    \n    # Drop iD column\n    new_data = new_data.drop(\"house_id\", axis=1)\n    \n    # Get dummy variables for city and house_type\n    new_data = pd.get_dummies(new_data, columns = [\"city\", \"house_type\"])\n    \n    # Extract useful information from sale_date column\n    new_data[\"sale_date\"] = pd.to_datetime(new_data['sale_date'])\n    new_data[\"year\"] = new_data[\"sale_date\"].dt.year\n    new_data[\"month\"] = new_data[\"sale_date\"].dt.month\n    new_data[\"day\"] = new_data[\"sale_date\"].dt.day\n    \n    new_data = new_data.drop(\"sale_date\", axis=1)\n            \n    return new_data\n        \ntrain_clean = transform_data(train_clean)\ntest_clean = transform_data(test_clean)\n\n# Split train_clean into X_train and y_train\nX_train = train_clean.drop(\"sale_price\", axis=1).values\ny_train = train_clean[\"sale_price\"].values\n\nX_test = test_clean.values\n\n# Create and fit model\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel_2 = RandomForestRegressor()\nmodel_2.fit(X_train, y_train)\n\ny_pred_2 = model_2.predict(X_test)\n\ncompare_result = pd.DataFrame({'house_id': test[\"house_id\"], 'price': y_pred_2})\n\n# Display the resulting dataframe\nprint(compare_result)","metadata":{"executionCancelledAt":null,"executionTime":392,"lastExecutedAt":1709603567739,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 5\n\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('validation.csv')\n\n#train_clean = data_cleaner(train)\n#test_clean = data_cleaner(test)\ntrain_clean = train\ntest_clean = test\n#print(train_clean.equals(train))\n#print(test_clean.equals(test))\n\n        # All data seem to be already clean\n\ndef transform_data(data):\n    new_data= data.copy()\n    \n    # Drop iD column\n    new_data = new_data.drop(\"house_id\", axis=1)\n    \n    # Get dummy variables for city and house_type\n    new_data = pd.get_dummies(new_data, columns = [\"city\", \"house_type\"])\n    \n    # Extract useful information from sale_date column\n    new_data[\"sale_date\"] = pd.to_datetime(new_data['sale_date'])\n    new_data[\"year\"] = new_data[\"sale_date\"].dt.year\n    new_data[\"month\"] = new_data[\"sale_date\"].dt.month\n    new_data[\"day\"] = new_data[\"sale_date\"].dt.day\n    \n    new_data = new_data.drop(\"sale_date\", axis=1)\n            \n    return new_data\n        \ntrain_clean = transform_data(train_clean)\ntest_clean = transform_data(test_clean)\n\n# Split train_clean into X_train and y_train\nX_train = train_clean.drop(\"sale_price\", axis=1).values\ny_train = train_clean[\"sale_price\"].values\n\nX_test = test_clean.values\n\n# Create and fit model\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel_2 = RandomForestRegressor()\nmodel_2.fit(X_train, y_train)\n\ny_pred_2 = model_2.predict(X_test)\n\ncompare_result = pd.DataFrame({'house_id': test[\"house_id\"], 'price': y_pred_2})\n\n# Display the resulting dataframe\nprint(compare_result)","outputsMetadata":{"0":{"height":297,"type":"stream"},"1":{"height":323,"type":"dataFrame"}}},"id":"538ffb3d-4008-49b6-9876-7831e025f5a4","cell_type":"code","execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":"     house_id      price\n0     1331375   81382.84\n1     1630115  306317.98\n2     1645745  400012.88\n3     1336775  106068.69\n4     1888274  267081.75\n..        ...        ...\n295   1986255  358878.35\n296   1896276  385318.45\n297   1758223  262584.98\n298   1752010  175009.76\n299   1651404  415645.21\n\n[300 rows x 2 columns]\n"}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}
